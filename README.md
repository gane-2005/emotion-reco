# Speech Emotion Analysis Using Voice

![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![Flask](https://img.shields.io/badge/Flask-3.0-green)
![React](https://img.shields.io/badge/React-18-61dafb)
![Vite](https://img.shields.io/badge/Vite-7.3-646cff)
![ML](https://img.shields.io/badge/ML-Scikit--learn-orange)

A comprehensive **full-stack machine learning application** that analyzes emotions from voice audio using advanced AI algorithms. Built for Learnthon competition with a modern React + Vite frontend and Flask backend.

## ğŸ¯ Project Overview

This application uses **machine learning** to detect human emotions from voice recordings. It supports:
- **7 Emotions**: Happy, Sad, Angry, Fear, Surprise, Disgust, Neutral
- **Real-time audio recording** via browser
- **File upload** for pre-recorded audio
- **Prediction history** with database storage
- **Beautiful UI** with emotion-specific themes

## âœ¨ Features

### Frontend (React + Vite)
- ğŸ¨ **Premium Dark UI** with glassmorphism effects
- ğŸ¤ **Live Audio Recording** using MediaRecorder API
- ğŸ“ **Drag & Drop Upload** with file validation
- ğŸ“Š **Real-time Results** with confidence scores
- ğŸ“œ **History Management** with CSV export
- ğŸ­ **Emotion-specific Themes** with smooth animations
- ğŸ“± **Fully Responsive** design

### Backend (Flask + Python)
- ğŸ”¬ **Advanced Feature Extraction** (MFCC, Chroma, Mel Spectrogram)
- ğŸ¤– **RandomForest Classifier** trained on RAVDESS dataset
- ğŸ’¾ **SQLite Database** for prediction history
- ğŸ”Œ **RESTful API** with CORS support
- âš¡ **Fast Response** times

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| **Frontend** | React 18, Vite, Axios |
| **Backend** | Python, Flask, Flask-CORS |
| **ML Framework** | Scikit-learn, Librosa |
| **Database** | SQLite |
| **Dataset** | RAVDESS (optional for training) |
| **Styling** | CSS3 with animations |

## ğŸ“‹ Prerequisites

- **Python 3.9+** installed
- **Node.js 18+** and npm installed
- Microphone access for recording
- Modern web browser (Chrome, Firefox, Edge)

## ğŸš€ Installation & Setup

### 1ï¸âƒ£ Clone or Navigate to Project

```bash
cd d:\learnthonproject\speech-emotion-analysis
```

### 2ï¸âƒ£ Backend Setup

```bash
# Navigate to backend
cd backend

# Create virtual environment (recommended)
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On Mac/Linux:
# source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Initialize database
python utils/database.py

# Train the model (creates demo model if no dataset available)
python model/train_model.py
```

### 3ï¸âƒ£ Frontend Setup

```bash
# Navigate to frontend (from project root)
cd frontend

# Dependencies are already installed, but if needed:
# npm install
```

## â–¶ï¸ Running the Application

### Start Backend Server

```bash
# From backend directory
python app.py
```

Backend will run at: `http://localhost:5000`

### Start Frontend Dev Server

```bash
# From frontend directory (in a new terminal)
npm run dev
```

Frontend will run at: `http://localhost:5173`

### Open Application

Visit **`http://localhost:5173`** in your browser

## ğŸ“– Usage

1. **Choose Input Method**:
   - **Upload**: Drag & drop or click to select an audio file (WAV, MP3, OGG, FLAC)
   - **Record**: Click "Start Recording", speak for 3-5 seconds, then click "Stop & Analyze"

2. **View Results**:
   - Primary emotion with confidence percentage
   - Detailed probability breakdown for all emotions
   - Emotion-specific color theme and emoji

3. **Manage History**:
   - View all past predictions in the history table
   - Export history to CSV for analysis
   - Delete individual predictions

## ğŸ“ Dataset Information

The model can be trained on the **RAVDESS** (Ryerson Audio-Visual Database of Emotional Speech and Song) dataset:

- **Download**: [RAVDESS on Zenodo](https://zenodo.org/record/1188976)
- **Size**: 7,356 files
- **Emotions**: 8 emotions (we map to 7)
- **Format**: WAV files

Place the dataset in `d:\learnthonproject\speech-emotion-analysis\dataset\` folder.

**Note**: A demo model is automatically created if the dataset is not available, perfect for testing!

## ğŸ“Š Model Performance

- **Algorithm**: RandomForestClassifier
- **Features**: MFCC (40), Chroma (12), Mel Spectrogram (128) = 180 features
- **Expected Accuracy**: 65-75% on RAVDESS (demo model is synthetic)
- **Training Time**: ~2-5 minutes on RAVDESS

## ğŸ”Œ API Documentation

### Health Check
```http
GET /api/health
```

### Predict Emotion
```http
POST /api/predict
Content-Type: multipart/form-data

Body: { audio: <audio_file> }
```

### Get History
```http
GET /api/history
```

### Delete Prediction
```http
DELETE /api/history/<prediction_id>
```

## ğŸ“ Project Structure

```
speech-emotion-analysis/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                 # Flask application
â”‚   â”œâ”€â”€ config.py              # Configuration
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ train_model.py     # ML training script
â”‚   â”‚   â”œâ”€â”€ emotion_model.pkl  # Trained model
â”‚   â”‚   â””â”€â”€ scaler.pkl         # Feature scaler
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ database.py        # Database operations
â”‚       â””â”€â”€ feature_extraction.py  # Audio feature extraction
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx            # Main component
â”‚   â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”œâ”€â”€ styles/            # CSS styling
â”‚   â”‚   â””â”€â”€ utils/             # API utilities
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â””â”€â”€ README.md
```

## ğŸ¨ Screenshots

The application features:
- Dark mode with gradient backgrounds
- Glassmorphism card effects
- Emotion-specific color schemes
- Animated confidence bars
- Responsive mobile design

## ğŸš§ Future Enhancements

- [ ] Deploy to cloud (Heroku/Railway)
- [ ] Add more emotion categories
- [ ] Implement CNN/LSTM for better accuracy
- [ ] Add multi-language support
- [ ] Real-time waveform visualization
- [ ] Export audio with predictions

## ğŸ† For Learnthon Judges

**Why This Project Stands Out**:

1. **Full-Stack Implementation**: Complete end-to-end solution
2. **Modern Tech Stack**: React + Vite (fast), Flask (reliable)
3. **Production-Ready**: Database, error handling, validation
4. **Great UX**: Beautiful design, smooth animations, responsive
5. **Practical ML**: Real-world audio processing with Librosa
6. **Extensible**: Clean code architecture, easy to enhance

## ğŸ¤ Contributing

This is a Learnthon project. Feedback and suggestions are welcome!

## ğŸ“ License

MIT License - Feel free to use for learning purposes

## ğŸ‘¨â€ğŸ’» Author

Built with â¤ï¸ for Learnthon

---

**Happy Emotion Analyzing! ğŸ¤ğŸ­**
